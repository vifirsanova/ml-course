### **Базовый уровень: Генерация текста с использованием LSTM**

0. **Сбор данных**: используйте готовый или соберите свой корпус в формате plain text для генерации текстов

1. Генерация текста на основе небольшого датасета
   - Предварительный анализ: чистка текста
   - Обучение модели. Используйте образец из туториала по RNNи
   - Генерация текста. Используйте образец из туториала по RNN
   - Сгенерируйте несколько текстов с помощью созданной модели

---

### **Продвинутый уровень: Машинный перевод с использованием LSTM**

0. **Сбор данных**: используйте готовый или соберите свой параллельный корпус (например, **OpenSubtitles**)
     
1. Реализация **seq2seq** модели

   - Построение модели **LSTM**, **GRU**, другая рекуррентная архитектура на выбор
   - Релизуем классы кодера и декодера

2. Опционально: добавление механизма внимания (**attention**)
   
   - Пример **tf.Attention**: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention
   
3. Оценка качества обучения с помощью **perplexity**, **BLEU score**, других метрик оценки
